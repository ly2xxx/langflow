{
  "id": "b28b53cf-d529-402f-acd5-4d1d8b7b2ac9",
  "data": {
    "nodes": [
      {
        "id": "MessagetoData-bKmC7",
        "type": "genericNode",
        "position": {
          "x": 702.6124245605195,
          "y": 16.53809695535054
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.io import MessageInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass MessageToDataComponent(Component):\n    display_name = \"Message to Data\"\n    description = \"Convert a Message object to a Data object\"\n    icon = \"message-square-share\"\n    beta = True\n    name = \"MessagetoData\"\n\n    inputs = [\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The Message object to convert to a Data object\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"convert_message_to_data\"),\n    ]\n\n    def convert_message_to_data(self) -> Data:\n        if isinstance(self.message, Message):\n            # Convert Message to Data\n            return Data(data=self.message.data)\n\n        msg = \"Error converting Message to Data: Input must be a Message object\"\n        logger.opt(exception=True).debug(msg)\n        self.status = msg\n        return Data(data={\"error\": msg})\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Message object to convert to a Data object",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              }
            },
            "description": "Convert a Message object to a Data object",
            "icon": "message-square-share",
            "base_classes": [
              "Data"
            ],
            "display_name": "Message to Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "convert_message_to_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "message"
            ],
            "beta": true,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "MessagetoData",
          "id": "MessagetoData-bKmC7"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 702.6124245605195,
          "y": 16.53809695535054
        },
        "dragging": false
      },
      {
        "id": "TextInput-ueUWs",
        "type": "genericNode",
        "position": {
          "x": 335.80901546500263,
          "y": 2.8966478567569993
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "Who is the CIO of HR Tech? And what's CTO's 2025 target milestone?",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "TextInput",
          "id": "TextInput-ueUWs"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 335.80901546500263,
          "y": 2.8966478567569993
        },
        "dragging": false
      },
      {
        "id": "ParseData-TquMO",
        "type": "genericNode",
        "position": {
          "x": 1425.6092267859792,
          "y": 77.1667596157665
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "({flow_id},,{timestamp}){text}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ParseData",
          "id": "ParseData-TquMO"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "positionAbsolute": {
          "x": 1425.6092267859792,
          "y": 77.1667596157665
        },
        "dragging": false
      },
      {
        "id": "SplitText-j4qpG",
        "type": "genericNode",
        "position": {
          "x": 1080.0258496216081,
          "y": -34.996266306002994
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data_inputs": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_inputs",
                "value": "",
                "display_name": "Data Inputs",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "chunk_overlap": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_overlap",
                "value": 0,
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1,
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of characters in each chunk.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, IntInput, MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk.\",\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=\"The character to split on. Defaults to newline.\",\n            value=\"\\n\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs):\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def split_text(self) -> list[Data]:\n        separator = unescape_string(self.separator)\n\n        documents = [_input.to_lc_document() for _input in self.data_inputs if isinstance(_input, Data)]\n\n        splitter = CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n        docs = splitter.split_documents(documents)\n        data = self._docs_to_data(docs)\n        self.status = data\n        return data\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separator": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "separator",
                "value": " ",
                "display_name": "Separator",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The character to split on. Defaults to newline.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text into chunks based on specified criteria.",
            "icon": "scissors-line-dashed",
            "base_classes": [
              "Data"
            ],
            "display_name": "Split Text",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "chunks",
                "display_name": "Chunks",
                "method": "split_text",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "SplitText",
          "id": "SplitText-j4qpG"
        },
        "selected": false,
        "width": 320,
        "height": 473,
        "positionAbsolute": {
          "x": 1080.0258496216081,
          "y": -34.996266306002994
        },
        "dragging": false
      },
      {
        "id": "TextOutput-IZvn5",
        "type": "genericNode",
        "position": {
          "x": 1781.8026199159224,
          "y": 92.3239252808705
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Display a text output in the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "TextOutput",
          "id": "TextOutput-IZvn5"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 1781.8026199159224,
          "y": 92.3239252808705
        },
        "dragging": false
      },
      {
        "id": "SemanticTextSplitter-HuV5h",
        "type": "genericNode",
        "position": {
          "x": 690.4866920284362,
          "y": 398.4986717159709
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data_inputs": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_inputs",
                "value": "",
                "display_name": "Data Inputs",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "List of Data objects containing text and metadata to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "embeddings": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embeddings",
                "value": "",
                "display_name": "Embeddings",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "Embeddings model to use for semantic similarity. Required.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "breakpoint_threshold_amount": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "breakpoint_threshold_amount",
                "value": 0.5,
                "display_name": "Breakpoint Threshold Amount",
                "advanced": false,
                "dynamic": false,
                "info": "Numerical amount for the breakpoint threshold.",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "breakpoint_threshold_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "percentile",
                  "standard_deviation",
                  "interquartile"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "breakpoint_threshold_type",
                "value": "interquartile",
                "display_name": "Breakpoint Threshold Type",
                "advanced": false,
                "dynamic": false,
                "info": "Method to determine breakpoints. Options: 'percentile', 'standard_deviation', 'interquartile'. Defaults to 'percentile'.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "buffer_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "buffer_size",
                "value": 0,
                "display_name": "Buffer Size",
                "advanced": true,
                "dynamic": false,
                "info": "Size of the buffer.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain.docstore.document import Document\nfrom langchain_experimental.text_splitter import SemanticChunker\n\nfrom langflow.base.textsplitters.model import LCTextSplitterComponent\nfrom langflow.io import (\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    MessageTextInput,\n    Output,\n)\nfrom langflow.schema import Data\n\n\nclass SemanticTextSplitterComponent(LCTextSplitterComponent):\n    \"\"\"Split text into semantically meaningful chunks using semantic similarity.\"\"\"\n\n    display_name: str = \"Semantic Text Splitter\"\n    name: str = \"SemanticTextSplitter\"\n    description: str = \"Split text into semantically meaningful chunks using semantic similarity.\"\n    documentation = \"https://python.langchain.com/docs/how_to/semantic-chunker/\"\n    beta = True  # this component is beta because it is imported from langchain_experimental\n    icon = \"LangChain\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"List of Data objects containing text and metadata to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        HandleInput(\n            name=\"embeddings\",\n            display_name=\"Embeddings\",\n            info=\"Embeddings model to use for semantic similarity. Required.\",\n            input_types=[\"Embeddings\"],\n            is_list=False,\n        ),\n        DropdownInput(\n            name=\"breakpoint_threshold_type\",\n            display_name=\"Breakpoint Threshold Type\",\n            info=(\n                \"Method to determine breakpoints. Options: 'percentile', \"\n                \"'standard_deviation', 'interquartile'. Defaults to 'percentile'.\"\n            ),\n            value=\"percentile\",\n            options=[\"percentile\", \"standard_deviation\", \"interquartile\"],\n        ),\n        FloatInput(\n            name=\"breakpoint_threshold_amount\",\n            display_name=\"Breakpoint Threshold Amount\",\n            info=\"Numerical amount for the breakpoint threshold.\",\n            value=0.5,\n        ),\n        IntInput(\n            name=\"number_of_chunks\",\n            display_name=\"Number of Chunks\",\n            info=\"Number of chunks to split the text into.\",\n            value=5,\n        ),\n        MessageTextInput(\n            name=\"sentence_split_regex\",\n            display_name=\"Sentence Split Regex\",\n            info=\"Regular expression to split sentences. Optional.\",\n            value=\"\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"buffer_size\",\n            display_name=\"Buffer Size\",\n            info=\"Size of the buffer.\",\n            value=0,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs: list[Document]) -> list[Data]:\n        \"\"\"Convert a list of Document objects to Data objects.\"\"\"\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def split_text(self) -> list[Data]:\n        \"\"\"Split the input data into semantically meaningful chunks.\"\"\"\n        try:\n            embeddings = getattr(self, \"embeddings\", None)\n            if embeddings is None:\n                error_msg = \"An embeddings model is required for SemanticTextSplitter.\"\n                raise ValueError(error_msg)\n\n            if not self.data_inputs:\n                error_msg = \"Data inputs cannot be empty.\"\n                raise ValueError(error_msg)\n\n            documents = []\n            for _input in self.data_inputs:\n                if isinstance(_input, Data):\n                    documents.append(_input.to_lc_document())\n                else:\n                    error_msg = f\"Invalid data input type: {_input}\"\n                    raise TypeError(error_msg)\n\n            if not documents:\n                error_msg = \"No valid Data objects found in data_inputs.\"\n                raise ValueError(error_msg)\n\n            texts = [doc.page_content for doc in documents]\n            metadatas = [doc.metadata for doc in documents]\n\n            splitter_params = {\n                \"embeddings\": embeddings,\n                \"breakpoint_threshold_type\": self.breakpoint_threshold_type or \"percentile\",\n                \"breakpoint_threshold_amount\": self.breakpoint_threshold_amount,\n                \"number_of_chunks\": self.number_of_chunks,\n                \"buffer_size\": self.buffer_size,\n            }\n\n            if self.sentence_split_regex:\n                splitter_params[\"sentence_split_regex\"] = self.sentence_split_regex\n\n            splitter = SemanticChunker(**splitter_params)\n            docs = splitter.create_documents(texts, metadatas=metadatas)\n\n            data = self._docs_to_data(docs)\n            self.status = data\n\n        except Exception as e:\n            error_msg = f\"An error occurred during semantic splitting: {e}\"\n            raise RuntimeError(error_msg) from e\n\n        else:\n            return data\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "number_of_chunks": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_chunks",
                "value": 5,
                "display_name": "Number of Chunks",
                "advanced": false,
                "dynamic": false,
                "info": "Number of chunks to split the text into.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "sentence_split_regex": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sentence_split_regex",
                "value": "",
                "display_name": "Sentence Split Regex",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Regular expression to split sentences. Optional.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text into semantically meaningful chunks using semantic similarity.",
            "icon": "LangChain",
            "base_classes": [
              "Data"
            ],
            "display_name": "Semantic Text Splitter",
            "documentation": "https://python.langchain.com/docs/how_to/semantic-chunker/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "chunks",
                "display_name": "Chunks",
                "method": "split_text",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data_inputs",
              "embeddings",
              "breakpoint_threshold_type",
              "breakpoint_threshold_amount",
              "number_of_chunks",
              "sentence_split_regex",
              "buffer_size"
            ],
            "beta": true,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "langchain_utilities",
            "key": "SemanticTextSplitter",
            "score": 0.09766125352057238,
            "lf_version": "1.1.1"
          },
          "type": "SemanticTextSplitter",
          "id": "SemanticTextSplitter-HuV5h"
        },
        "selected": false,
        "width": 320,
        "height": 521,
        "positionAbsolute": {
          "x": 690.4866920284362,
          "y": 398.4986717159709
        },
        "dragging": false
      },
      {
        "id": "ParseData-SAsdL",
        "type": "genericNode",
        "position": {
          "x": 1067.900117089525,
          "y": 524.303146736334
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "({flow_id},,{timestamp}){text}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ParseData",
          "id": "ParseData-SAsdL"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "positionAbsolute": {
          "x": 1067.900117089525,
          "y": 524.303146736334
        },
        "dragging": false
      },
      {
        "id": "TextOutput-zmO1U",
        "type": "genericNode",
        "position": {
          "x": 1451.3764084166553,
          "y": 530.3660130023754
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Display a text output in the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "TextOutput",
          "id": "TextOutput-zmO1U"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 1451.3764084166553,
          "y": 530.3660130023754
        },
        "dragging": false
      },
      {
        "id": "OllamaEmbeddings-JR3sn",
        "type": "genericNode",
        "position": {
          "x": 320.6518497998988,
          "y": 410.6244042480541
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "base_url": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "base_url",
                "value": "http://localhost:11434",
                "display_name": "Ollama Base URL",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_ollama import OllamaEmbeddings\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import MessageTextInput, Output\n\n\nclass OllamaEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Ollama Embeddings\"\n    description: str = \"Generate embeddings using Ollama models.\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n    icon = \"Ollama\"\n    name = \"OllamaEmbeddings\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"model\",\n            display_name=\"Ollama Model\",\n            value=\"nomic-embed-text\",\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Ollama Base URL\",\n            value=\"http://localhost:11434\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            output = OllamaEmbeddings(model=self.model, base_url=self.base_url)\n        except Exception as e:\n            msg = \"Could not connect to Ollama API.\"\n            raise ValueError(msg) from e\n        return output\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "nomic-embed-text",
                "display_name": "Ollama Model",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generate embeddings using Ollama models.",
            "icon": "Ollama",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "Ollama Embeddings",
            "documentation": "https://python.langchain.com/docs/integrations/text_embedding/ollama",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "model",
              "base_url"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "embeddings",
            "key": "OllamaEmbeddings",
            "score": 0.000052003277518821525,
            "lf_version": "1.1.1"
          },
          "type": "OllamaEmbeddings",
          "id": "OllamaEmbeddings-JR3sn"
        },
        "selected": false,
        "width": 320,
        "height": 319
      },
      {
        "id": "OllamaModel-b0IFh",
        "type": "genericNode",
        "position": {
          "x": 690.486692028436,
          "y": 959.3138013248183
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "base_url": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "base_url",
                "value": "http://localhost:11434",
                "display_name": "Base URL",
                "advanced": false,
                "dynamic": false,
                "info": "Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\nfrom langchain_ollama import ChatOllama\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, StrInput\n\n\nclass ChatOllamaComponent(LCModelComponent):\n    display_name = \"Ollama\"\n    description = \"Generate text using Ollama Local LLMs.\"\n    icon = \"Ollama\"\n    name = \"OllamaModel\"\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name == \"mirostat\":\n            if field_value == \"Disabled\":\n                build_config[\"mirostat_eta\"][\"advanced\"] = True\n                build_config[\"mirostat_tau\"][\"advanced\"] = True\n                build_config[\"mirostat_eta\"][\"value\"] = None\n                build_config[\"mirostat_tau\"][\"value\"] = None\n\n            else:\n                build_config[\"mirostat_eta\"][\"advanced\"] = False\n                build_config[\"mirostat_tau\"][\"advanced\"] = False\n\n                if field_value == \"Mirostat 2.0\":\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.2\n                    build_config[\"mirostat_tau\"][\"value\"] = 10\n                else:\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.1\n                    build_config[\"mirostat_tau\"][\"value\"] = 5\n\n        if field_name == \"model_name\":\n            base_url_dict = build_config.get(\"base_url\", {})\n            base_url_load_from_db = base_url_dict.get(\"load_from_db\", False)\n            base_url_value = base_url_dict.get(\"value\")\n            if base_url_load_from_db:\n                base_url_value = self.variables(base_url_value, field_name)\n            elif not base_url_value:\n                base_url_value = \"http://localhost:11434\"\n            build_config[\"model_name\"][\"options\"] = self.get_model(base_url_value)\n        if field_name == \"keep_alive_flag\":\n            if field_value == \"Keep\":\n                build_config[\"keep_alive\"][\"value\"] = \"-1\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            elif field_value == \"Immediately\":\n                build_config[\"keep_alive\"][\"value\"] = \"0\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            else:\n                build_config[\"keep_alive\"][\"advanced\"] = False\n\n        return build_config\n\n    def get_model(self, base_url_value: str) -> list[str]:\n        try:\n            url = urljoin(base_url_value, \"/api/tags\")\n            with httpx.Client() as client:\n                response = client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n                return [model[\"name\"] for model in data.get(\"models\", [])]\n        except Exception as e:\n            msg = \"Could not retrieve models. Please, make sure Ollama is running.\"\n            raise ValueError(msg) from e\n\n    inputs = [\n        StrInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            info=\"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n            value=\"http://localhost:11434\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            value=\"llama3.1\",\n            info=\"Refer to https://ollama.com/library for more models.\",\n            refresh_button=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.2,\n            info=\"Controls the creativity of model responses.\",\n        ),\n        StrInput(\n            name=\"format\", display_name=\"Format\", info=\"Specify the format of the output (e.g., json).\", advanced=True\n        ),\n        DictInput(name=\"metadata\", display_name=\"Metadata\", info=\"Metadata to add to the run trace.\", advanced=True),\n        DropdownInput(\n            name=\"mirostat\",\n            display_name=\"Mirostat\",\n            options=[\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n            info=\"Enable/disable Mirostat sampling for controlling perplexity.\",\n            value=\"Disabled\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        FloatInput(\n            name=\"mirostat_eta\",\n            display_name=\"Mirostat Eta\",\n            info=\"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"mirostat_tau\",\n            display_name=\"Mirostat Tau\",\n            info=\"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_ctx\",\n            display_name=\"Context Window Size\",\n            info=\"Size of the context window for generating tokens. (Default: 2048)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_gpu\",\n            display_name=\"Number of GPUs\",\n            info=\"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_thread\",\n            display_name=\"Number of Threads\",\n            info=\"Number of threads to use during computation. (Default: detected for optimal performance)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"repeat_last_n\",\n            display_name=\"Repeat Last N\",\n            info=\"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"repeat_penalty\",\n            display_name=\"Repeat Penalty\",\n            info=\"Penalty for repetitions in generated text. (Default: 1.1)\",\n            advanced=True,\n        ),\n        FloatInput(name=\"tfs_z\", display_name=\"TFS Z\", info=\"Tail free sampling value. (Default: 1)\", advanced=True),\n        IntInput(name=\"timeout\", display_name=\"Timeout\", info=\"Timeout for the request stream.\", advanced=True),\n        IntInput(\n            name=\"top_k\", display_name=\"Top K\", info=\"Limits token selection to top K. (Default: 40)\", advanced=True\n        ),\n        FloatInput(name=\"top_p\", display_name=\"Top P\", info=\"Works together with top-k. (Default: 0.9)\", advanced=True),\n        BoolInput(name=\"verbose\", display_name=\"Verbose\", info=\"Whether to print out response text.\", advanced=True),\n        StrInput(\n            name=\"tags\",\n            display_name=\"Tags\",\n            info=\"Comma-separated list of tags to add to the run trace.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"stop_tokens\",\n            display_name=\"Stop Tokens\",\n            info=\"Comma-separated list of tokens to signal the model to stop generating text.\",\n            advanced=True,\n        ),\n        StrInput(name=\"system\", display_name=\"System\", info=\"System to use for generating text.\", advanced=True),\n        StrInput(name=\"template\", display_name=\"Template\", info=\"Template to use for generating text.\", advanced=True),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n        *LCModelComponent._base_inputs,\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(self.mirostat, 0)\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n        else:\n            mirostat_eta = self.mirostat_eta\n            mirostat_tau = self.mirostat_tau\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": self.base_url,\n            \"model\": self.model_name,\n            \"mirostat\": mirostat_value,\n            \"format\": self.format,\n            \"metadata\": self.metadata,\n            \"tags\": self.tags.split(\",\") if self.tags else None,\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": self.num_ctx or None,\n            \"num_gpu\": self.num_gpu or None,\n            \"num_thread\": self.num_thread or None,\n            \"repeat_last_n\": self.repeat_last_n or None,\n            \"repeat_penalty\": self.repeat_penalty or None,\n            \"temperature\": self.temperature or None,\n            \"stop\": self.stop_tokens.split(\",\") if self.stop_tokens else None,\n            \"system\": self.system,\n            \"template\": self.template,\n            \"tfs_z\": self.tfs_z or None,\n            \"timeout\": self.timeout or None,\n            \"top_k\": self.top_k or None,\n            \"top_p\": self.top_p or None,\n            \"verbose\": self.verbose,\n        }\n\n        # Remove parameters with None values\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)\n        except Exception as e:\n            msg = \"Could not initialize Ollama LLM.\"\n            raise ValueError(msg) from e\n\n        return output\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "format": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "format",
                "value": "",
                "display_name": "Format",
                "advanced": true,
                "dynamic": false,
                "info": "Specify the format of the output (e.g., json).",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "metadata": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "metadata",
                "value": {},
                "display_name": "Metadata",
                "advanced": true,
                "dynamic": false,
                "info": "Metadata to add to the run trace.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "mirostat": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Disabled",
                  "Mirostat",
                  "Mirostat 2.0"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mirostat",
                "value": "Disabled",
                "display_name": "Mirostat",
                "advanced": true,
                "dynamic": false,
                "info": "Enable/disable Mirostat sampling for controlling perplexity.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "mirostat_eta": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mirostat_eta",
                "value": "",
                "display_name": "Mirostat Eta",
                "advanced": true,
                "dynamic": false,
                "info": "Learning rate for Mirostat algorithm. (Default: 0.1)",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "mirostat_tau": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mirostat_tau",
                "value": "",
                "display_name": "Mirostat Tau",
                "advanced": true,
                "dynamic": false,
                "info": "Controls the balance between coherence and diversity of the output. (Default: 5.0)",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gemma2:2b",
                  "qwen2.5-coder:latest",
                  "nomic-embed-text:latest",
                  "llama3.1:8b",
                  "starcoder2:3b",
                  "llama3.2:latest",
                  "llama3.1:latest"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "llama3.2:latest",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "Refer to https://ollama.com/library for more models.",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "num_ctx": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "num_ctx",
                "value": "",
                "display_name": "Context Window Size",
                "advanced": true,
                "dynamic": false,
                "info": "Size of the context window for generating tokens. (Default: 2048)",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "num_gpu": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "num_gpu",
                "value": "",
                "display_name": "Number of GPUs",
                "advanced": true,
                "dynamic": false,
                "info": "Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "num_thread": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "num_thread",
                "value": "",
                "display_name": "Number of Threads",
                "advanced": true,
                "dynamic": false,
                "info": "Number of threads to use during computation. (Default: detected for optimal performance)",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "repeat_last_n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "repeat_last_n",
                "value": "",
                "display_name": "Repeat Last N",
                "advanced": true,
                "dynamic": false,
                "info": "How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "repeat_penalty": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "repeat_penalty",
                "value": "",
                "display_name": "Repeat Penalty",
                "advanced": true,
                "dynamic": false,
                "info": "Penalty for repetitions in generated text. (Default: 1.1)",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "stop_tokens": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stop_tokens",
                "value": "",
                "display_name": "Stop Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "Comma-separated list of tokens to signal the model to stop generating text.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system",
                "value": "",
                "display_name": "System",
                "advanced": true,
                "dynamic": false,
                "info": "System to use for generating text.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "tags": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tags",
                "value": "",
                "display_name": "Tags",
                "advanced": true,
                "dynamic": false,
                "info": "Comma-separated list of tags to add to the run trace.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "Controls the creativity of model responses.",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "template": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "",
                "display_name": "Template",
                "advanced": true,
                "dynamic": false,
                "info": "Template to use for generating text.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "tfs_z": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tfs_z",
                "value": "",
                "display_name": "TFS Z",
                "advanced": true,
                "dynamic": false,
                "info": "Tail free sampling value. (Default: 1)",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "timeout",
                "value": "",
                "display_name": "Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "Timeout for the request stream.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "top_k": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_k",
                "value": "",
                "display_name": "Top K",
                "advanced": true,
                "dynamic": false,
                "info": "Limits token selection to top K. (Default: 40)",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "top_p": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_p",
                "value": "",
                "display_name": "Top P",
                "advanced": true,
                "dynamic": false,
                "info": "Works together with top-k. (Default: 0.9)",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": false,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to print out response text.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Generate text using Ollama Local LLMs.",
            "icon": "Ollama",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Ollama",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "hidden": null,
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "hidden": null,
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "base_url",
              "model_name",
              "temperature",
              "format",
              "metadata",
              "mirostat",
              "mirostat_eta",
              "mirostat_tau",
              "num_ctx",
              "num_gpu",
              "num_thread",
              "repeat_last_n",
              "repeat_penalty",
              "tfs_z",
              "timeout",
              "top_k",
              "top_p",
              "verbose",
              "tags",
              "stop_tokens",
              "system",
              "template",
              "output_parser",
              "input_value",
              "system_message",
              "stream"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "models",
            "key": "OllamaModel",
            "score": 0.001,
            "lf_version": "1.1.1"
          },
          "type": "OllamaModel",
          "id": "OllamaModel-b0IFh"
        },
        "selected": false,
        "width": 320,
        "height": 669,
        "positionAbsolute": {
          "x": 690.486692028436,
          "y": 959.3138013248183
        },
        "dragging": false
      },
      {
        "id": "TextOutput-d2kJG",
        "type": "genericNode",
        "position": {
          "x": 1057.2901011239528,
          "y": 862.6110843814546
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Display a text output in the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "outputs",
            "key": "TextOutput",
            "score": 0.003169567463043492,
            "lf_version": "1.1.1"
          },
          "type": "TextOutput",
          "id": "TextOutput-d2kJG"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 1057.2901011239528,
          "y": 862.6110843814546
        },
        "dragging": false
      },
      {
        "id": "Prompt-yWQRZ",
        "type": "genericNode",
        "position": {
          "x": 317.6204166668783,
          "y": 1252.1502419746273
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are a language specialist expert in finding department keyword from natural language questions.\n\nGiven the {Input} question from user, extract the most relevant department keyword(s) that identifies a department, only give the direct extracted keyword(s) delimited by ',' (no need to explain the reasoning process)  -\nQuestion: {input}\nAnswer:\n\nFor example -\nQuestion: Who is the tech lead of CIW\nAnswer: CIW\n\nQuestion: What's CDU's 2025 milestone target\nAnswer: CDU",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "Input": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "Input",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "input": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "input",
                "display_name": "input",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Find Keyword Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "Input",
                "input"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Prompt",
          "id": "Prompt-yWQRZ"
        },
        "selected": false,
        "width": 320,
        "height": 431,
        "positionAbsolute": {
          "x": 317.6204166668783,
          "y": 1252.1502419746273
        },
        "dragging": false
      },
      {
        "id": "CharacterTextSplitter-hLbTD",
        "type": "genericNode",
        "position": {
          "x": 1893.9656458376924,
          "y": 1152.4160918982432
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data_input": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_input",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Data"
                ],
                "dynamic": false,
                "info": "The texts to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "chunk_overlap": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_overlap",
                "value": 200,
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "The amount of overlap between chunks.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum length of each chunk.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\n\nfrom langchain_text_splitters import CharacterTextSplitter, TextSplitter\n\nfrom langflow.base.textsplitters.model import LCTextSplitterComponent\nfrom langflow.inputs import DataInput, IntInput, MessageTextInput\nfrom langflow.utils.util import unescape_string\n\n\nclass CharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name = \"CharacterTextSplitter\"\n    description = \"Split text by number of characters.\"\n    documentation = \"https://docs.langflow.org/components/text-splitters#charactertextsplitter\"\n    name = \"CharacterTextSplitter\"\n    icon = \"LangChain\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info='The characters to split on.\\nIf left empty defaults to \"\\\\n\\\\n\".',\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        separator = unescape_string(self.separator) if self.separator else \"\\n\\n\"\n        return CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separator": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "separator",
                "value": "",
                "display_name": "Separator",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The characters to split on.\nIf left empty defaults to \"\\n\\n\".",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text by number of characters.",
            "icon": "LangChain",
            "base_classes": [
              "Data"
            ],
            "display_name": "CharacterTextSplitter",
            "documentation": "https://docs.langflow.org/components/text-splitters#charactertextsplitter",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "transform_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "chunk_size",
              "chunk_overlap",
              "data_input",
              "separator"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "langchain_utilities",
            "key": "CharacterTextSplitter",
            "score": 0.007761458725589881,
            "lf_version": "1.1.1"
          },
          "type": "CharacterTextSplitter",
          "id": "CharacterTextSplitter-hLbTD"
        },
        "selected": false,
        "width": 320,
        "height": 453,
        "positionAbsolute": {
          "x": 1893.9656458376924,
          "y": 1152.4160918982432
        },
        "dragging": false
      },
      {
        "id": "Directory-DFC6K",
        "type": "genericNode",
        "position": {
          "x": 1896.9970789707131,
          "y": 650.7139083833013
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data, retrieve_file_paths\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, IntInput, MessageTextInput\nfrom langflow.schema import Data\nfrom langflow.template import Output\n\n\nclass DirectoryComponent(Component):\n    display_name = \"Directory\"\n    description = \"Recursively load files from a directory.\"\n    icon = \"folder\"\n    name = \"Directory\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"path\",\n            display_name=\"Path\",\n            info=\"Path to the directory to load files from.\",\n        ),\n        MessageTextInput(\n            name=\"types\",\n            display_name=\"Types\",\n            info=\"File types to load. Leave empty to load all default supported types.\",\n            is_list=True,\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth\",\n            info=\"Depth to search for files.\",\n            value=0,\n        ),\n        IntInput(\n            name=\"max_concurrency\",\n            display_name=\"Max Concurrency\",\n            advanced=True,\n            info=\"Maximum concurrency for loading files.\",\n            value=2,\n        ),\n        BoolInput(\n            name=\"load_hidden\",\n            display_name=\"Load Hidden\",\n            advanced=True,\n            info=\"If true, hidden files will be loaded.\",\n        ),\n        BoolInput(\n            name=\"recursive\",\n            display_name=\"Recursive\",\n            advanced=True,\n            info=\"If true, the search will be recursive.\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"Use Multithreading\",\n            advanced=True,\n            info=\"If true, multithreading will be used.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_directory\"),\n    ]\n\n    def load_directory(self) -> list[Data]:\n        path = self.path\n        types = (\n            self.types if self.types and self.types != [\"\"] else TEXT_FILE_TYPES\n        )  # self.types is already a list due to is_list=True\n        depth = self.depth\n        max_concurrency = self.max_concurrency\n        load_hidden = self.load_hidden\n        recursive = self.recursive\n        silent_errors = self.silent_errors\n        use_multithreading = self.use_multithreading\n\n        resolved_path = self.resolve_path(path)\n        file_paths = retrieve_file_paths(\n            resolved_path, load_hidden=load_hidden, recursive=recursive, depth=depth, types=types\n        )\n\n        if types:\n            file_paths = [fp for fp in file_paths if any(fp.endswith(ext) for ext in types)]\n\n        loaded_data = []\n\n        if use_multithreading:\n            loaded_data = parallel_load_data(file_paths, silent_errors=silent_errors, max_concurrency=max_concurrency)\n        else:\n            loaded_data = [parse_text_file_to_data(file_path, silent_errors=silent_errors) for file_path in file_paths]\n        loaded_data = list(filter(None, loaded_data))\n        self.status = loaded_data\n        return loaded_data  # type: ignore[return-value]\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "depth": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "depth",
                "value": 0,
                "display_name": "Depth",
                "advanced": false,
                "dynamic": false,
                "info": "Depth to search for files.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "load_hidden": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "load_hidden",
                "value": false,
                "display_name": "Load Hidden",
                "advanced": true,
                "dynamic": false,
                "info": "If true, hidden files will be loaded.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_concurrency": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_concurrency",
                "value": 2,
                "display_name": "Max Concurrency",
                "advanced": true,
                "dynamic": false,
                "info": "Maximum concurrency for loading files.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "path": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "path",
                "value": "E:\\code2\\langflow\\SampleFlows\\RAG\\input",
                "display_name": "Path",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Path to the directory to load files from.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "recursive": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "recursive",
                "value": false,
                "display_name": "Recursive",
                "advanced": true,
                "dynamic": false,
                "info": "If true, the search will be recursive.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "silent_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "silent_errors",
                "value": false,
                "display_name": "Silent Errors",
                "advanced": true,
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "types": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "types",
                "value": [
                  "md"
                ],
                "display_name": "Types",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "File types to load. Leave empty to load all default supported types.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "use_multithreading": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "use_multithreading",
                "value": false,
                "display_name": "Use Multithreading",
                "advanced": true,
                "dynamic": false,
                "info": "If true, multithreading will be used.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Recursively load files from a directory.",
            "icon": "folder",
            "base_classes": [
              "Data"
            ],
            "display_name": "Directory",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "load_directory",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "path",
              "types",
              "depth",
              "max_concurrency",
              "load_hidden",
              "recursive",
              "silent_errors",
              "use_multithreading"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "data",
            "key": "Directory",
            "score": 0.001,
            "lf_version": "1.1.1"
          },
          "type": "Directory",
          "id": "Directory-DFC6K"
        },
        "selected": false,
        "width": 320,
        "height": 405
      },
      {
        "id": "SplitText-vguy1",
        "type": "genericNode",
        "position": {
          "x": 1439.5538191978756,
          "y": 978.1086867495469
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data_inputs": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_inputs",
                "value": "",
                "display_name": "Data Inputs",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "chunk_overlap": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_overlap",
                "value": 0,
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1,
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of characters in each chunk.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, IntInput, MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk.\",\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=\"The character to split on. Defaults to newline.\",\n            value=\"\\n\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs):\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def split_text(self) -> list[Data]:\n        separator = unescape_string(self.separator)\n\n        documents = [_input.to_lc_document() for _input in self.data_inputs if isinstance(_input, Data)]\n\n        splitter = CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n        docs = splitter.split_documents(documents)\n        data = self._docs_to_data(docs)\n        self.status = data\n        return data\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separator": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "separator",
                "value": ",",
                "display_name": "Separator",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The character to split on. Defaults to newline.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text into chunks based on specified criteria.",
            "icon": "scissors-line-dashed",
            "base_classes": [
              "Data"
            ],
            "display_name": "Split Text",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "chunks",
                "display_name": "Chunks",
                "method": "split_text",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "SplitText",
          "id": "SplitText-vguy1"
        },
        "selected": false,
        "width": 320,
        "height": 473,
        "positionAbsolute": {
          "x": 1439.5538191978756,
          "y": 978.1086867495469
        },
        "dragging": false
      },
      {
        "id": "UpdateData-mO9yX",
        "type": "genericNode",
        "position": {
          "x": 1036.3732125061092,
          "y": 1546.805542504249
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "old_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "old_data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The record to update.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import (\n    BoolInput,\n    DataInput,\n    DictInput,\n    IntInput,\n    MessageTextInput,\n)\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass UpdateDataComponent(Component):\n    display_name: str = \"Update Data\"\n    description: str = \"Dynamically update or append data with the specified fields.\"\n    name: str = \"UpdateData\"\n    MAX_FIELDS = 15  # Define a constant for maximum number of fields\n    icon = \"FolderSync\"\n\n    inputs = [\n        DataInput(\n            name=\"old_data\",\n            display_name=\"Data\",\n            info=\"The record to update.\",\n            is_list=True,  # Changed to True to handle list of Data objects\n        ),\n        IntInput(\n            name=\"number_of_fields\",\n            display_name=\"Number of Fields\",\n            info=\"Number of fields to be added to the record.\",\n            real_time_refresh=True,\n            value=0,\n            range_spec=RangeSpec(min=1, max=MAX_FIELDS, step=1, step_type=\"int\"),\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key that identifies the field to be used as the text content.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"text_key_validator\",\n            display_name=\"Text Key Validator\",\n            advanced=True,\n            info=\"If enabled, checks if the given 'Text Key' is present in the given 'Data'.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"build_data\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        \"\"\"Update the build configuration when the number of fields changes.\n\n        Args:\n            build_config (dotdict): The current build configuration.\n            field_value (Any): The new value for the field.\n            field_name (Optional[str]): The name of the field being updated.\n        \"\"\"\n        if field_name == \"number_of_fields\":\n            default_keys = {\n                \"code\",\n                \"_type\",\n                \"number_of_fields\",\n                \"text_key\",\n                \"old_data\",\n                \"text_key_validator\",\n            }\n            try:\n                field_value_int = int(field_value)\n            except ValueError:\n                return build_config\n\n            if field_value_int > self.MAX_FIELDS:\n                build_config[\"number_of_fields\"][\"value\"] = self.MAX_FIELDS\n                msg = f\"Number of fields cannot exceed {self.MAX_FIELDS}. \" \"Try using a Component to combine two Data.\"\n                raise ValueError(msg)\n\n            existing_fields = {}\n            # Back up the existing template fields\n            for key in list(build_config.keys()):\n                if key not in default_keys:\n                    existing_fields[key] = build_config.pop(key)\n\n            for i in range(1, field_value_int + 1):\n                key = f\"field_{i}_key\"\n                if key in existing_fields:\n                    field = existing_fields[key]\n                    build_config[key] = field\n                else:\n                    field = DictInput(\n                        display_name=f\"Field {i}\",\n                        name=key,\n                        info=f\"Key for field {i}.\",\n                        input_types=[\"Text\", \"Data\"],\n                    )\n                    build_config[field.name] = field.to_dict()\n\n            build_config[\"number_of_fields\"][\"value\"] = field_value_int\n        return build_config\n\n    async def build_data(self) -> Data | list[Data]:\n        \"\"\"Build the updated data by combining the old data with new fields.\"\"\"\n        new_data = self.get_data()\n        if isinstance(self.old_data, list):\n            for data_item in self.old_data:\n                if not isinstance(data_item, Data):\n                    continue  # Skip invalid items\n                data_item.data.update(new_data)\n                if self.text_key:\n                    data_item.text_key = self.text_key\n                self.validate_text_key(data_item)\n            self.status = self.old_data\n            return self.old_data  # Returns List[Data]\n        if isinstance(self.old_data, Data):\n            self.old_data.data.update(new_data)\n            if self.text_key:\n                self.old_data.text_key = self.text_key\n            self.status = self.old_data\n            self.validate_text_key(self.old_data)\n            return self.old_data  # Returns Data\n        msg = \"old_data is not a Data object or list of Data objects.\"\n        raise ValueError(msg)\n\n    def get_data(self):\n        \"\"\"Function to get the Data from the attributes.\"\"\"\n        data = {}\n        default_keys = {\n            \"code\",\n            \"_type\",\n            \"number_of_fields\",\n            \"text_key\",\n            \"old_data\",\n            \"text_key_validator\",\n        }\n        for attr_name, attr_value in self._attributes.items():\n            if attr_name in default_keys:\n                continue  # Skip default attributes\n            if isinstance(attr_value, dict):\n                for key, value in attr_value.items():\n                    data[key] = value.get_text() if isinstance(value, Data) else value\n            elif isinstance(attr_value, Data):\n                data[attr_name] = attr_value.get_text()\n            else:\n                data[attr_name] = attr_value\n        return data\n\n    def validate_text_key(self, data: Data) -> None:\n        \"\"\"This function validates that the Text Key is one of the keys in the Data.\"\"\"\n        data_keys = data.data.keys()\n        if self.text_key and self.text_key not in data_keys:\n            msg = f\"Text Key: '{self.text_key}' not found in the Data keys: \" f\"{', '.join(data_keys)}\"\n            raise ValueError(msg)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "number_of_fields": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "int",
                  "min": 1,
                  "max": 15,
                  "step": 1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_fields",
                "value": 1,
                "display_name": "Number of Fields",
                "advanced": false,
                "dynamic": false,
                "info": "Number of fields to be added to the record.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "text_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_key",
                "value": "",
                "display_name": "Text Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Key that identifies the field to be used as the text content.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text_key_validator": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_key_validator",
                "value": false,
                "display_name": "Text Key Validator",
                "advanced": true,
                "dynamic": false,
                "info": "If enabled, checks if the given 'Text Key' is present in the given 'Data'.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "field_1_key": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "field_1_key",
                "value": {
                  "keyword": ""
                },
                "display_name": "Field 1",
                "advanced": false,
                "input_types": [
                  "Text",
                  "Data"
                ],
                "dynamic": false,
                "info": "Key for field 1.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              }
            },
            "description": "Dynamically update or append data with the specified fields.",
            "icon": "FolderSync",
            "base_classes": [
              "Data"
            ],
            "display_name": "Update Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "hidden": null,
                "display_name": "Data",
                "method": "build_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null
              }
            ],
            "field_order": [
              "old_data",
              "number_of_fields",
              "text_key",
              "text_key_validator"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "UpdateData",
          "id": "UpdateData-mO9yX"
        },
        "selected": false,
        "width": 320,
        "height": 387,
        "positionAbsolute": {
          "x": 1036.3732125061092,
          "y": 1546.805542504249
        },
        "dragging": false
      },
      {
        "id": "ParseData-uqoB2",
        "type": "genericNode",
        "position": {
          "x": 1407.7237713011566,
          "y": 1668.0628678250807
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{text}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ParseData",
          "id": "ParseData-uqoB2"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "positionAbsolute": {
          "x": 1407.7237713011566,
          "y": 1668.0628678250807
        },
        "dragging": false
      },
      {
        "id": "TextOutput-NcBJ6",
        "type": "genericNode",
        "position": {
          "x": 1826.0615436580258,
          "y": 1696.861482588778
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Display a text output in the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "TextOutput",
          "id": "TextOutput-NcBJ6"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 1826.0615436580258,
          "y": 1696.861482588778
        },
        "dragging": false
      },
      {
        "id": "MessagetoData-nFQyU",
        "type": "genericNode",
        "position": {
          "x": 1056.0775278707445,
          "y": 1133.0149198469103
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.io import MessageInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass MessageToDataComponent(Component):\n    display_name = \"Message to Data\"\n    description = \"Convert a Message object to a Data object\"\n    icon = \"message-square-share\"\n    beta = True\n    name = \"MessagetoData\"\n\n    inputs = [\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The Message object to convert to a Data object\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"convert_message_to_data\"),\n    ]\n\n    def convert_message_to_data(self) -> Data:\n        if isinstance(self.message, Message):\n            # Convert Message to Data\n            return Data(data=self.message.data)\n\n        msg = \"Error converting Message to Data: Input must be a Message object\"\n        logger.opt(exception=True).debug(msg)\n        self.status = msg\n        return Data(data={\"error\": msg})\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Message object to convert to a Data object",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              }
            },
            "description": "Convert a Message object to a Data object",
            "icon": "message-square-share",
            "base_classes": [
              "Data"
            ],
            "display_name": "Message to Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "convert_message_to_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "message"
            ],
            "beta": true,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "MessagetoData",
          "id": "MessagetoData-nFQyU"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 1056.0775278707445,
          "y": 1133.0149198469103
        },
        "dragging": false
      },
      {
        "id": "ParseData-bf4yp",
        "type": "genericNode",
        "position": {
          "x": 2257.1313351735835,
          "y": 804.1044249141536
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{file_path}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ParseData",
          "id": "ParseData-bf4yp"
        },
        "selected": true,
        "width": 320,
        "height": 309,
        "positionAbsolute": {
          "x": 2257.1313351735835,
          "y": 804.1044249141536
        },
        "dragging": false
      },
      {
        "id": "TextOutput-PH5ao",
        "type": "genericNode",
        "position": {
          "x": 2276.8356505382194,
          "y": 1210.3164647389403
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Display a text output in the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "type": "TextOutput",
          "id": "TextOutput-PH5ao"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 2276.8356505382194,
          "y": 1210.3164647389403
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "TextInput-ueUWs",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-ueUWsœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MessagetoData-bKmC7",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œMessagetoData-bKmC7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "MessagetoData-bKmC7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-ueUWs",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-ueUWs{œdataTypeœ:œTextInputœ,œidœ:œTextInput-ueUWsœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-MessagetoData-bKmC7{œfieldNameœ:œmessageœ,œidœ:œMessagetoData-bKmC7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "MessagetoData-bKmC7",
        "sourceHandle": "{œdataTypeœ:œMessagetoDataœ,œidœ:œMessagetoData-bKmC7œ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "SplitText-j4qpG",
        "targetHandle": "{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-j4qpGœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-j4qpG",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "MessagetoData",
            "id": "MessagetoData-bKmC7",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-MessagetoData-bKmC7{œdataTypeœ:œMessagetoDataœ,œidœ:œMessagetoData-bKmC7œ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-SplitText-j4qpG{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-j4qpGœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "SplitText-j4qpG",
        "sourceHandle": "{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-j4qpGœ,œnameœ:œchunksœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-TquMO",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-TquMOœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-TquMO",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-j4qpG",
            "name": "chunks",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-SplitText-j4qpG{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-j4qpGœ,œnameœ:œchunksœ,œoutput_typesœ:[œDataœ]}-ParseData-TquMO{œfieldNameœ:œdataœ,œidœ:œParseData-TquMOœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "ParseData-TquMO",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-TquMOœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextOutput-IZvn5",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-IZvn5œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-IZvn5",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-TquMO",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-TquMO{œdataTypeœ:œParseDataœ,œidœ:œParseData-TquMOœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-TextOutput-IZvn5{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-IZvn5œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "ParseData-SAsdL",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-SAsdLœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextOutput-zmO1U",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-zmO1Uœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-zmO1U",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-SAsdL",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-SAsdL{œdataTypeœ:œParseDataœ,œidœ:œParseData-SAsdLœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-TextOutput-zmO1U{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-zmO1Uœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "MessagetoData-bKmC7",
        "sourceHandle": "{œdataTypeœ:œMessagetoDataœ,œidœ:œMessagetoData-bKmC7œ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "SemanticTextSplitter-HuV5h",
        "targetHandle": "{œfieldNameœ:œdata_inputsœ,œidœ:œSemanticTextSplitter-HuV5hœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SemanticTextSplitter-HuV5h",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "MessagetoData",
            "id": "MessagetoData-bKmC7",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-MessagetoData-bKmC7{œdataTypeœ:œMessagetoDataœ,œidœ:œMessagetoData-bKmC7œ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-SemanticTextSplitter-HuV5h{œfieldNameœ:œdata_inputsœ,œidœ:œSemanticTextSplitter-HuV5hœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "SemanticTextSplitter-HuV5h",
        "sourceHandle": "{œdataTypeœ:œSemanticTextSplitterœ,œidœ:œSemanticTextSplitter-HuV5hœ,œnameœ:œchunksœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-SAsdL",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-SAsdLœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-SAsdL",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "SemanticTextSplitter",
            "id": "SemanticTextSplitter-HuV5h",
            "name": "chunks",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-SemanticTextSplitter-HuV5h{œdataTypeœ:œSemanticTextSplitterœ,œidœ:œSemanticTextSplitter-HuV5hœ,œnameœ:œchunksœ,œoutput_typesœ:[œDataœ]}-ParseData-SAsdL{œfieldNameœ:œdataœ,œidœ:œParseData-SAsdLœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "OllamaEmbeddings-JR3sn",
        "sourceHandle": "{œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-JR3snœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "SemanticTextSplitter-HuV5h",
        "targetHandle": "{œfieldNameœ:œembeddingsœ,œidœ:œSemanticTextSplitter-HuV5hœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embeddings",
            "id": "SemanticTextSplitter-HuV5h",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OllamaEmbeddings",
            "id": "OllamaEmbeddings-JR3sn",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-OllamaEmbeddings-JR3sn{œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-JR3snœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-SemanticTextSplitter-HuV5h{œfieldNameœ:œembeddingsœ,œidœ:œSemanticTextSplitter-HuV5hœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "OllamaModel-b0IFh",
        "sourceHandle": "{œdataTypeœ:œOllamaModelœ,œidœ:œOllamaModel-b0IFhœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextOutput-d2kJG",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-d2kJGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-d2kJG",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OllamaModel",
            "id": "OllamaModel-b0IFh",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OllamaModel-b0IFh{œdataTypeœ:œOllamaModelœ,œidœ:œOllamaModel-b0IFhœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TextOutput-d2kJG{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-d2kJGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "TextInput-ueUWs",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-ueUWsœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-yWQRZ",
        "targetHandle": "{œfieldNameœ:œInputœ,œidœ:œPrompt-yWQRZœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "Input",
            "id": "Prompt-yWQRZ",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-ueUWs",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-ueUWs{œdataTypeœ:œTextInputœ,œidœ:œTextInput-ueUWsœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-yWQRZ{œfieldNameœ:œInputœ,œidœ:œPrompt-yWQRZœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-yWQRZ",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-yWQRZœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OllamaModel-b0IFh",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOllamaModel-b0IFhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OllamaModel-b0IFh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-yWQRZ",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-yWQRZ{œdataTypeœ:œPromptœ,œidœ:œPrompt-yWQRZœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OllamaModel-b0IFh{œfieldNameœ:œinput_valueœ,œidœ:œOllamaModel-b0IFhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "Directory-DFC6K",
        "sourceHandle": "{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-DFC6Kœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "CharacterTextSplitter-hLbTD",
        "targetHandle": "{œfieldNameœ:œdata_inputœ,œidœ:œCharacterTextSplitter-hLbTDœ,œinputTypesœ:[œDocumentœ,œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data_input",
            "id": "CharacterTextSplitter-hLbTD",
            "inputTypes": [
              "Document",
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "Directory",
            "id": "Directory-DFC6K",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-Directory-DFC6K{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-DFC6Kœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-CharacterTextSplitter-hLbTD{œfieldNameœ:œdata_inputœ,œidœ:œCharacterTextSplitter-hLbTDœ,œinputTypesœ:[œDocumentœ,œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "SplitText-vguy1",
        "sourceHandle": "{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-vguy1œ,œnameœ:œchunksœ,œoutput_typesœ:[œDataœ]}",
        "target": "UpdateData-mO9yX",
        "targetHandle": "{œfieldNameœ:œold_dataœ,œidœ:œUpdateData-mO9yXœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "old_data",
            "id": "UpdateData-mO9yX",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-vguy1",
            "name": "chunks",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-SplitText-vguy1{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-vguy1œ,œnameœ:œchunksœ,œoutput_typesœ:[œDataœ]}-UpdateData-mO9yX{œfieldNameœ:œold_dataœ,œidœ:œUpdateData-mO9yXœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "UpdateData-mO9yX",
        "sourceHandle": "{œdataTypeœ:œUpdateDataœ,œidœ:œUpdateData-mO9yXœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-uqoB2",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-uqoB2œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-uqoB2",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "UpdateData",
            "id": "UpdateData-mO9yX",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-UpdateData-mO9yX{œdataTypeœ:œUpdateDataœ,œidœ:œUpdateData-mO9yXœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParseData-uqoB2{œfieldNameœ:œdataœ,œidœ:œParseData-uqoB2œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "ParseData-uqoB2",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-uqoB2œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextOutput-NcBJ6",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-NcBJ6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-NcBJ6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-uqoB2",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-uqoB2{œdataTypeœ:œParseDataœ,œidœ:œParseData-uqoB2œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-TextOutput-NcBJ6{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-NcBJ6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "TextOutput-d2kJG",
        "sourceHandle": "{œdataTypeœ:œTextOutputœ,œidœ:œTextOutput-d2kJGœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MessagetoData-nFQyU",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œMessagetoData-nFQyUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "MessagetoData-nFQyU",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextOutput",
            "id": "TextOutput-d2kJG",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextOutput-d2kJG{œdataTypeœ:œTextOutputœ,œidœ:œTextOutput-d2kJGœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-MessagetoData-nFQyU{œfieldNameœ:œmessageœ,œidœ:œMessagetoData-nFQyUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "MessagetoData-nFQyU",
        "sourceHandle": "{œdataTypeœ:œMessagetoDataœ,œidœ:œMessagetoData-nFQyUœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "SplitText-vguy1",
        "targetHandle": "{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-vguy1œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-vguy1",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "MessagetoData",
            "id": "MessagetoData-nFQyU",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-MessagetoData-nFQyU{œdataTypeœ:œMessagetoDataœ,œidœ:œMessagetoData-nFQyUœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-SplitText-vguy1{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-vguy1œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "Directory-DFC6K",
        "sourceHandle": "{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-DFC6Kœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-bf4yp",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-bf4ypœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-bf4yp",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "Directory",
            "id": "Directory-DFC6K",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-Directory-DFC6K{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-DFC6Kœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParseData-bf4yp{œfieldNameœ:œdataœ,œidœ:œParseData-bf4ypœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "source": "ParseData-bf4yp",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-bf4ypœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextOutput-PH5ao",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-PH5aoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-PH5ao",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-bf4yp",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-bf4yp{œdataTypeœ:œParseDataœ,œidœ:œParseData-bf4ypœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-TextOutput-PH5ao{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-PH5aoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "viewport": {
      "x": -418.1513262074644,
      "y": -327.5110748808572,
      "zoom": 0.6597539553864471
    }
  },
  "description": "Your Toolkit for Text Generation.",
  "name": "Text processing",
  "last_tested_version": "1.1.1",
  "endpoint_name": "Text-processing-flow",
  "is_component": false
}